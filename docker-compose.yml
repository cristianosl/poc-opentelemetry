services:
  # ==================== Backend ====================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: poc-metrics-backend
    ports:
      - "8080:8080"
    environment:
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      - OTEL_SERVICE_NAME=poc-metrics-backend
      - ENVIRONMENT=local
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0
    depends_on:
      otel-collector:
        condition: service_started
      clickhouse:
        condition: service_healthy
    networks:
      - poc-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ==================== OpenTelemetry Collector ====================
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.96.0
    container_name: poc-otel-collector
    command: ["--config=/etc/otelcol-contrib/config.yaml"]
    ports:
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
      - "8888:8888"   # Métricas do próprio collector
      - "13133:13133" # Health check
      - "55679:55679" # zPages
    volumes:
      - ./otel-collector/config.yaml:/etc/otelcol-contrib/config.yaml:ro
    depends_on:
      clickhouse:
        condition: service_healthy
      mimir:
        condition: service_started
      otel-timescale-adapter:
        condition: service_started
    networks:
      - poc-network

  # ==================== OpenTelemetry to TimescaleDB Adapter ====================
  otel-timescale-adapter:
    build:
      context: ./otel-timescale-adapter
      dockerfile: Dockerfile
    container_name: poc-otel-timescale-adapter
    ports:
      - "4319:4317"   # OTLP gRPC (porta diferente para evitar conflito)
    environment:
      - OTLP_PORT=4317
      - TIMESCALE_HOST=timescaledb
      - TIMESCALE_PORT=5432
      - TIMESCALE_DB=metrics
      - TIMESCALE_USER=metrics
      - TIMESCALE_PASSWORD=metrics
    depends_on:
      timescaledb:
        condition: service_healthy
    networks:
      - poc-network
    healthcheck:
      test: ["CMD", "python", "-c", "import grpc; from opentelemetry.proto.collector.metrics.v1 import metrics_service_pb2_grpc; import socket; s=socket.socket(); s.connect(('localhost', 4317)); s.close()"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # ==================== ClickHouse ====================
  clickhouse:
    image: clickhouse/clickhouse-server:24.1
    container_name: poc-clickhouse
    ports:
      - "8123:8123"   # HTTP interface
      - "9000:9000"   # Native TCP interface
    environment:
      - CLICKHOUSE_DB=otel
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    volumes:
      - clickhouse-data:/var/lib/clickhouse
      - clickhouse-logs:/var/log/clickhouse-server
      - ./databases/clickhouse/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - poc-network
    healthcheck:
      test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    ulimits:
      nofile:
        soft: 262144
        hard: 262144

  # ==================== PostgreSQL + TimescaleDB ====================
  timescaledb:
    image: timescale/timescaledb:2.14.0-pg16
    container_name: poc-timescaledb
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=metrics
      - POSTGRES_PASSWORD=metrics
      - POSTGRES_DB=metrics
    volumes:
      - timescale-data:/var/lib/postgresql/data
      - ./databases/timescaledb/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - poc-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U metrics -d metrics"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # ==================== MinIO (Storage para Mimir) ====================
  minio:
    image: minio/minio:latest
    container_name: poc-minio
    ports:
      - "9001:9001"   # Console
      - "9002:9000"   # API (porta alterada para evitar conflito com ClickHouse)
    environment:
      - MINIO_ROOT_USER=mimir
      - MINIO_ROOT_PASSWORD=supersecret
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    networks:
      - poc-network
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # MinIO Init - Cria buckets necessários
  minio-init:
    image: minio/mc:latest
    container_name: poc-minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 mimir supersecret;
      mc mb myminio/mimir-blocks --ignore-existing;
      mc mb myminio/mimir-ruler --ignore-existing;
      mc anonymous set public myminio/mimir-blocks;
      exit 0;
      "
    networks:
      - poc-network

  # ==================== Mimir ====================
  mimir:
    image: grafana/mimir:2.11.0
    container_name: poc-mimir
    ports:
      - "9009:9009"   # HTTP API
      - "9095:9095"   # gRPC
    command: ["-config.file=/etc/mimir/config.yaml"]
    volumes:
      - ./mimir/config.yaml:/etc/mimir/config.yaml:ro
      - mimir-data:/data
    depends_on:
      minio-init:
        condition: service_completed_successfully
    networks:
      - poc-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9009/ready"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  # ==================== Metabase ClickHouse Driver ====================
  metabase-clickhouse-driver:
    image: alpine:3.19
    container_name: poc-metabase-driver-init
    volumes:
      - metabase-plugins:/plugins
    command: >
      sh -c "
        apk add --no-cache curl;
        echo 'Downloading ClickHouse driver for Metabase...';
        curl -L -o /plugins/clickhouse.metabase-driver.jar https://github.com/ClickHouse/metabase-clickhouse-driver/releases/download/1.3.1/clickhouse.metabase-driver.jar;
        chmod 777 /plugins;
        chmod 666 /plugins/*.jar;
        echo 'Driver downloaded successfully!';
        ls -la /plugins/;
      "
    networks:
      - poc-network

  # ==================== Metabase ====================
  metabase:
    image: metabase/metabase:v0.48.11
    container_name: poc-metabase
    ports:
      - "3000:3000"
    environment:
      - MB_DB_TYPE=h2
      - MB_DB_FILE=/metabase-data/metabase.db
      - JAVA_TIMEZONE=America/Sao_Paulo
      - MB_PLUGINS_DIR=/plugins
    volumes:
      - metabase-data:/metabase-data
      - metabase-plugins:/plugins
    depends_on:
      clickhouse:
        condition: service_healthy
      timescaledb:
        condition: service_healthy
      metabase-clickhouse-driver:
        condition: service_completed_successfully
    networks:
      - poc-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

  # ==================== Grafana (opcional - para Mimir) ====================
  grafana:
    image: grafana/grafana:10.2.0
    container_name: poc-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      mimir:
        condition: service_healthy
    networks:
      - poc-network

networks:
  poc-network:
    driver: bridge

volumes:
  clickhouse-data:
  clickhouse-logs:
  timescale-data:
  minio-data:
  mimir-data:
  metabase-data:
  metabase-plugins:
  grafana-data:
